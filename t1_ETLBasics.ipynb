{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a60efa-64fd-4ed8-a542-60d21de2a2ca",
   "metadata": {},
   "source": [
    "# Progetto DataMining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35872ddd-7a6a-4fc1-bb6c-57140bc33802",
   "metadata": {},
   "source": [
    "### Introduzione al dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2bdb4b-66bb-4f19-acdf-f67e200e6923",
   "metadata": {},
   "source": [
    "Il datatset utilizzato per questo progetto può essere scaricato al seguente link: [https://datasets.simula.no/pmdata/](https://datasets.simula.no/pmdata/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6e1cd-4c45-4cf7-85c2-ad2a6eac8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json as json\n",
    "from datetime import datetime\n",
    "import dateutil as du"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8781b9",
   "metadata": {},
   "source": [
    "Di seguito va inserito il percorso della cartella che contiene i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed383c5-5af9-487d-bd11-127229e2920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../pmdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561188fc-55ca-41ec-a51c-d4bd9c9946b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calories_to_df(root_path, partecipants):\n",
    "    \"\"\"Funzione che dal file json delle calorie lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -return: dataframe contenente i dati\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    calories_file = 'calories.json'\n",
    "    for p_id in partecipants: \n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        with open(p_folder + calories_file) as file:\n",
    "            dict_cal = json.load(file)\n",
    "        for d in dict_cal:\n",
    "            d['TS'] = du.parser.parse(d['dateTime'])\n",
    "            d['calories'] = float(d['value'])\n",
    "            d.pop('dateTime')\n",
    "            d.pop('value')\n",
    "        df_cal = pd.DataFrame.from_dict(dict_cal)\n",
    "        df_cal['partecipant'] = p_id\n",
    "        df_cal = df_cal.set_index(['partecipant','TS'])\n",
    "        dfs.append(df_cal)\n",
    "    r = pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110b75d-03b1-4f83-bfc3-0e9482ff1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "calories = calories_to_df(PATH,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06dd64-0ae4-4fb2-b03e-480ed71e0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "calories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7dcf9a-92a9-4be9-b6b1-fb7dbdaecab1",
   "metadata": {},
   "source": [
    "**OSS:** La parte appena scritta è stata implementata guardando il file del professore per poter capire meglio e per iniziare mettendo mano sul dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498189a-b056-47b7-b800-d6cee690f390",
   "metadata": {},
   "source": [
    "# Data Mining Project (part 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da1588-50e9-4c59-872a-48a265b3a81e",
   "metadata": {},
   "source": [
    "Write a  function similar to\n",
    "```python\n",
    "calories_to_df\n",
    "```\n",
    "\n",
    "For the json files:\n",
    "\n",
    "- sedentary_minutes.json\n",
    "- distance.json\n",
    "- sleep.json\n",
    "- exercise.json\n",
    "- heart_rate.json\n",
    "- steps.json\n",
    "- lightly_active_minutes.json\n",
    "- time_in_heart_rate_zones.json\n",
    "- moderately_active_minutes.json\n",
    "- very_active_minutes.json\n",
    "- resting_heart_rate.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abedcd46-f543-4f37-8794-dcc95e5eea9b",
   "metadata": {},
   "source": [
    "Implementazione della funzione \n",
    "```python\n",
    "x_minutes_df\n",
    "```\n",
    "Per la creazione del dataFrame partendo dai file che rappresentano l'attività **x_minutes.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f48e3b2-da41-4f63-ac9e-44da135e6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_minutes_df(root_path,partecipants,n_file):\n",
    "    \"\"\"Funzione che dal file json lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -param n_file: nome del file da andare a trasformare\n",
    "    -return: dataframe contenente i dati\n",
    "    \n",
    "    (utilizzare per i file contenente i minutes)\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for p_id in partecipants:\n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        sed_min_file = n_file\n",
    "        with open(p_folder + sed_min_file) as file:\n",
    "            dict_sed_min = json.load(file)\n",
    "        for d in dict_sed_min:\n",
    "            d['TS'] = du.parser.parse(d['dateTime'])\n",
    "            d['mins'] = int(d['value'])\n",
    "            d.pop('dateTime')\n",
    "            d.pop('value')\n",
    "        df_sed_min = pd.DataFrame.from_dict(dict_sed_min)\n",
    "        df_sed_min['partecipant'] = p_id\n",
    "        df_sed_min = df_sed_min.set_index(['partecipant','TS'])\n",
    "        dfs.append(df_sed_min)\n",
    "    r = pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    return r\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab572fd-8ac4-467e-861a-0f01c0afd659",
   "metadata": {},
   "source": [
    "Per la creazione del dataFrame partendo dal file **sedentary_minutes.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e30f3-9885-4985-a369-749898efd047",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedentary_minutes = x_minutes_df(PATH,[1,2],'sedentary_minutes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a0eaa-262b-4afa-a6ed-e7c6493227d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedentary_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe829a-b68a-4aac-abe7-6b86362573ae",
   "metadata": {},
   "source": [
    "Per la creazione del dataFrame partendo dal file **moderately_active_minutes.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43989b5-eca2-41f4-aaa2-47c57e21a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "moderately_active_minutes = x_minutes_df(PATH,[1,2],'moderately_active_minutes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8444a9-4bb2-4dcd-b512-a347a843bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "moderately_active_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df41d13-ceae-428d-874f-987665c8af85",
   "metadata": {},
   "source": [
    "Per la creazione del dataFrame partendo dal file **lightly_active_minutes.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5a5a2-e8ba-4c82-a992-7c18a1900641",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightly_active_minutes = x_minutes_df(PATH,[1,1],'lightly_active_minutes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c71fe1b-54bd-4f4a-aac2-d0cfe2297d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightly_active_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea15626-142e-43e7-8ca4-402eed0f1b0e",
   "metadata": {},
   "source": [
    "Per la creazione del dataFrame partendo dal file **very_active_minutes.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8957f6a-b9a9-49ce-bce0-8c28e0fe3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_active_minutes = x_minutes_df(PATH,[1,1],'very_active_minutes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c07ea-6f49-4531-bc4a-be84810fba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_active_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea435e61-8187-4e08-9488-bd7777929bfa",
   "metadata": {},
   "source": [
    "Implementazione della funzione \n",
    "```python\n",
    "distance_to_df\n",
    "```\n",
    "Per la creazione del dataFrame partendo dal file **distance.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dad728-c470-4e69-a817-69be733a1827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_df(root_path,partecipants):\n",
    "    \"\"\"Funzione che dal file json distance lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -return: dataframe contenente i dati\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for p_id in partecipants:\n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        distance_file = 'distance.json'\n",
    "        with open(p_folder + distance_file) as file:\n",
    "            dict_distance = json.load(file)\n",
    "        for d in dict_distance:\n",
    "            d['TS'] = du.parser.parse(d['dateTime'])\n",
    "            d['distance'] = int(d['value'])\n",
    "            d.pop('dateTime')\n",
    "            d.pop('value')\n",
    "        df_distance = pd.DataFrame.from_dict(dict_distance)\n",
    "        df_distance['partecipant'] = p_id\n",
    "        df_distance = df_distance.set_index(['partecipant','TS'])\n",
    "        dfs.append(df_distance)\n",
    "    r = pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e37ee6-2021-44a7-b87b-b482beab7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = distance_to_df(PATH,[1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341965c-d456-418e-a6fc-bbcced6b95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5082e-9ba7-4aad-af61-95eef8aa2cf6",
   "metadata": {},
   "source": [
    "Implementazione della funzione \n",
    "```python\n",
    "heart_rate_to_df\n",
    "```\n",
    "Per la creazione del dataFrame partendo dal file **heart_rate.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2be3e5-51e6-4861-8e0e-4c6812484dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heart_rate_to_df(root_path,partecipants):\n",
    "    \"\"\"Funzione che dal file json heart_rate lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -return: dataframe contenente i dati\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for p_id in partecipants:\n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        hr_file = 'heart_rate.json'\n",
    "        with open(p_folder + hr_file) as file:\n",
    "            dict_hr = json.load(file)\n",
    "        for d in dict_hr:\n",
    "            d['TS'] = du.parser.parse(d['dateTime'])\n",
    "            d['bpm'] = d[\"value\"][\"bpm\"]\n",
    "            d['confidence'] = d[\"value\"][\"confidence\"]\n",
    "            d.pop('dateTime')\n",
    "            d.pop('value')\n",
    "        df_hr = pd.DataFrame.from_dict(dict_hr)\n",
    "        df_hr['partecipant'] = p_id\n",
    "        df_hr = df_hr.set_index(['partecipant','TS'])\n",
    "        dfs.append(df_hr)\n",
    "    r = pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f925dd3-9991-4637-ad19-2dd9770a28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate = heart_rate_to_df(PATH,[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b201958-0fd9-4143-9c78-85e9bba56947",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb4f94-f611-4fa5-ae65-2a48c45ae982",
   "metadata": {},
   "source": [
    "Implementazione della funzione \n",
    "```python\n",
    "sleep_to_df\n",
    "```\n",
    "Per la creazione del dataFrame partendo dal file **sleep.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cf4d8-6dcd-42f4-89d1-84ac92db8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_to_df(root_path,partecipants):\n",
    "    \"\"\"Funzione che dal file json sleep lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -return: dataframe contenente i dati\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for p_id in partecipants:\n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        sleep_file = 'sleep.json'\n",
    "        with open(p_folder + sleep_file) as file:\n",
    "            dict_sleep = json.load(file)\n",
    "        for d in dict_sleep:\n",
    "            d['startT'] = du.parser.parse(d['startTime'])\n",
    "            d['endT'] = du.parser.parse(d['endTime'])\n",
    "            if 'deep' in d['levels']['summary']:\n",
    "                d['levelDeep'] = d['levels']['summary']['deep']\n",
    "            if 'wake' in d['levels']['summary']:\n",
    "                d['levelWake'] = d['levels']['summary']['wake']\n",
    "            if 'light' in d['levels']['summary']:\n",
    "                d['levelLight'] = d['levels']['summary']['light']\n",
    "            if 'rem' in d['levels']['summary']:\n",
    "                d['levelRem'] = d['levels']['summary']['rem']\n",
    "            if 'shortData' in d['levels']:  \n",
    "                d['shortData'] = d['levels']['shortData']\n",
    "            d['data'] = d['levels']['data']\n",
    "            d.pop('startTime')\n",
    "            d.pop('endTime')\n",
    "            d.pop('logId')\n",
    "            d.pop('infoCode')\n",
    "            d.pop('levels')\n",
    "            d.pop('minutesToFallAsleep')\n",
    "        df_sleep = pd.DataFrame.from_dict(dict_sleep)\n",
    "        df_sleep['partecipants'] = p_id\n",
    "        df_sleep = df_sleep.set_index(['partecipants','dateOfSleep'])\n",
    "        dfs.append(df_sleep)\n",
    "    r = pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c1402-6609-4670-9984-8743151ad613",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep= sleep_to_df(PATH,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c5d0d-f586-4410-a214-520a423f171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d797f75-d9fe-4778-8c09-cb06f2a2ae98",
   "metadata": {},
   "source": [
    "Implementazione della funzione \n",
    "```python\n",
    "exercise_to_df\n",
    "```\n",
    "Per la creazione del dataFrame partendo dal file **exercise.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860724cd-aaaf-45fe-8bac-e204b0b69652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_to_df(root_path,partecipants):\n",
    "    \"\"\"Funzione che dal file json exercise lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -return: dataframe contenente i dati\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for p_id in partecipants:\n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        exercise_file = 'exercise.json'\n",
    "        with open(p_folder + exercise_file) as file:\n",
    "            dict_exercise = json.load(file)\n",
    "        \n",
    "        for d in dict_exercise:\n",
    "            d['start'] = du.parser.parse(d['startTime'])\n",
    "            d['activityLevelSedentary'] = d['activityLevel'][0]\n",
    "            d['activityLevelLightly'] = d['activityLevel'][1]\n",
    "            d['activityLevelFairly'] = d['activityLevel'][2]\n",
    "            d['activityLevelVery'] = d['activityLevel'][3]\n",
    "            if 'heartRateZones' in d:\n",
    "                d['heartRateZonesOutofRange'] = d['heartRateZones'][0]\n",
    "                d['heartRateZonesFatBurn'] = d['heartRateZones'][1]\n",
    "                d['heartRateZonesCardio'] = d['heartRateZones'][2]\n",
    "                d['heartRateZonesPeak'] = d['heartRateZones'][3]\n",
    "            else:\n",
    "                d['heartRateZonesOutofRange'] = None\n",
    "                d['heartRateZonesFatBurn'] = None\n",
    "                d['heartRateZonesCardio'] = None\n",
    "                d['heartRateZonesPeak'] = None\n",
    "            d.pop('activityTypeId')\n",
    "            d.pop('logId')\n",
    "            d.pop('logType')\n",
    "            d.pop('lastModified')\n",
    "            d.pop('originalStartTime')\n",
    "            d.pop('hasGps')\n",
    "            d.pop('shouldFetchDetails')\n",
    "            d.pop('originalDuration')\n",
    "            d.pop('activityLevel')\n",
    "            if 'heartRateZones' in d:\n",
    "                d.pop('heartRateZones')\n",
    "            \n",
    "        df_exercise = pd.DataFrame.from_dict(dict_exercise)\n",
    "        df_exercise['partecipants'] = p_id\n",
    "        df_exercise = df_exercise.set_index(['partecipants','start'])\n",
    "        dfs.append(df_exercise) \n",
    "    r = pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    r = r.fillna(0)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b57a2c-60d0-4f9a-8a42-442ea4390aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise = exercise_to_df(PATH,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c96af6-b5d9-4c0d-88a8-451dd9b911d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48dd748-a9ca-4f81-a891-e7cb67a7ad47",
   "metadata": {},
   "source": [
    "Implementazione della funzione \n",
    "```python\n",
    "steps_to_df\n",
    "```\n",
    "Per la creazione del dataFrame partendo dal file **steps.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2029b-2a2e-4a99-a949-f2c85677476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps_to_df(root_path,partecipants):\n",
    "    \"\"\"Funzione che dal file json steos lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -return: dataframe contenente i dati\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for p_id in partecipants:\n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        steps_file = 'steps.json'\n",
    "        with open(p_folder + steps_file) as file:\n",
    "            dict_steps = json.load(file)\n",
    "        for d in dict_steps:\n",
    "            d['TS'] = du.parser.parse(d['dateTime'])\n",
    "            d['STEPS'] = int(d['value'])\n",
    "            d.pop('dateTime')\n",
    "            d.pop('value')\n",
    "        df_steps = pd.DataFrame.from_dict(dict_steps)\n",
    "        df_steps['partecipant'] = p_id\n",
    "        df_steps = df_steps.set_index(['partecipant','TS'])\n",
    "        dfs.append(df_steps)\n",
    "    r = pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462eb8be-037f-4ad6-9883-c1f57da44b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = steps_to_df(PATH,[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51adc6-7ae2-4b6b-ab57-cf08180ee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eeb0ba-2bcf-4e17-a9c7-8d899461188c",
   "metadata": {},
   "source": [
    "Implementazione della funzione \n",
    "```python\n",
    "time_in_hr_zones_to_df\n",
    "```\n",
    "Per la creazione del dataFrame partendo dal file **time_in_heart_rate_zones.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911938e6-1251-4ac5-b08a-719e0ab0735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_in_hr_zones_to_df(root_path,partecipants):\n",
    "    \"\"\"Funzione che dal file json time_in_heart_rate_zones lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -return: dataframe contenente i dati\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for p_id in partecipants:\n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        t_hr_zones_file = 'time_in_heart_rate_zones.json'\n",
    "        with open(p_folder + t_hr_zones_file) as file:\n",
    "            dict_t_hr_zones = json.load(file)\n",
    "        for d in dict_t_hr_zones:\n",
    "            d['TS'] = du.parser.parse(d['dateTime'])\n",
    "            d['times_Zone1'] = d[\"value\"][\"valuesInZones\"]['IN_DEFAULT_ZONE_1']\n",
    "            d['times_Zone2'] = d[\"value\"][\"valuesInZones\"]['IN_DEFAULT_ZONE_2']\n",
    "            d['times_Zone3'] = d[\"value\"][\"valuesInZones\"]['IN_DEFAULT_ZONE_3']\n",
    "            d['times_below_def_zone1'] = d[\"value\"][\"valuesInZones\"]['BELOW_DEFAULT_ZONE_1']\n",
    "            d.pop('dateTime')\n",
    "            d.pop('value')\n",
    "        df_t_hr_zones = pd.DataFrame.from_dict(dict_t_hr_zones)\n",
    "        df_t_hr_zones['partecipant'] = p_id\n",
    "        df_t_hr_zones = df_t_hr_zones.set_index(['partecipant','TS'])\n",
    "        dfs.append(df_t_hr_zones)\n",
    "    r = pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60dfce-c2ef-4d3c-84bb-aca546624f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_in_heart_rate_zones = time_in_hr_zones_to_df(PATH,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a7d06-8164-4edd-b5f3-7eae1dddf11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_in_heart_rate_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cd8b8-f893-4769-80fd-d4eb717e7fc9",
   "metadata": {},
   "source": [
    "Implementazione della funzione \n",
    "```python\n",
    "resting_heart_rate_to_df\n",
    "```\n",
    "Per la creazione del dataFrame partendo dal file **resting_heart_rate.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65090aa-8f20-42d8-859e-d36be9c00862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resting_heart_rate_to_df(root_path,partecipants):\n",
    "    \"\"\"Funzione che dal file json resting_heart_rate lo trasforma in un dataframe.\n",
    "    \n",
    "    -param root_path: il percorso del file\n",
    "    -param partecipanti: partecipanti presi in considerazione. es [1,2]\n",
    "    -return: dataframe contenente i dati\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    resting_hr_file = 'resting_heart_rate.json'\n",
    "    for p_id in partecipants:\n",
    "        p_folder = root_path + \"p{:02d}\".format(p_id) + '/fitbit/'\n",
    "        with open(p_folder + resting_hr_file) as file:\n",
    "            dict_resting_hr = json.load(file)\n",
    "        for d in dict_resting_hr:\n",
    "            d['TS'] = du.parser.parse(d['dateTime'])\n",
    "            d['rest'] = d['value']['value']\n",
    "            d['error'] = d['value']['error']\n",
    "            d.pop('dateTime')\n",
    "            d.pop('value')\n",
    "            \n",
    "        df_resting_hr = pd.DataFrame.from_dict(dict_resting_hr)\n",
    "        df_resting_hr['partecipant'] = p_id\n",
    "        df_resting_hr = df_resting_hr.set_index(['partecipant','TS'])\n",
    "        dfs.append(df_resting_hr)\n",
    "    r= pd.concat(dfs)\n",
    "    r = r.sort_index()\n",
    "    \n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa57482-c474-438d-b062-c70e9b401d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resting_hr = resting_heart_rate_to_df(PATH, [1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7304830-aa97-4126-9c50-25b011973596",
   "metadata": {},
   "outputs": [],
   "source": [
    "resting_hr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94b51f-720e-4b0c-8a3b-d781577a7963",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scelte sui Dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88d7a8-184b-42cb-ad4a-e599678a7178",
   "metadata": {},
   "source": [
    "Per i seguenti file ho mantenuto la stessa struttura del json:\n",
    "- calories.json\n",
    "- distance.json\n",
    "- sedentary_minutes.json\n",
    "- lightly_active_minutes.json\n",
    "- moderately_active_minutes.json\n",
    "- very_active_minutes.json\n",
    "- steps.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2c06d-81b6-409a-a1b6-e1f2148b14c3",
   "metadata": {},
   "source": [
    "Invece per il file **exercise.json** ho deciso di eliminare la lista `activityLevel` e creare una colonna per ogni elemento della lista: activityLevelSedentary, activityLevelLightly, activityLevelFairly e activityLevelVery. In modo simile è stato fatto per la lista `heartRateZones` generando heartRateZonesOutofRange, heartRateZonesFatBurn, heartRateZonesCardio, heartRateZonesPeak. Nella creazione del dataFrame ho omesso:\n",
    "- logId, perchè introducendo per ogni riga il numero del partecipante non ho bisogno di identificare l'attività;\n",
    "- activityTypeId;\n",
    "- duration;\n",
    "- logType;\n",
    "- manualValuesSpecified;\n",
    "- lastModified;\n",
    "- originalStartTime;\n",
    "- originalDuration;\n",
    "- hasGps;\n",
    "- shouldFetchDetails;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3097ed4-04fd-473b-909d-4a8a09504aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
